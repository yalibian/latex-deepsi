##############################################################
## Incremental formalization
##############################################################
@inproceedings{shipman1994supporting,
  title={Supporting knowledge-base evolution with incremental formalization},
  author={Shipman III, Frank M and McCall, Raymond},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={285--291},
  year={1994},
  organization={ACM}
}


@inproceedings{yang2007evaluating,
 author = {Yang, Jun and Jiang, Yu-Gang and Hauptmann, Alexander G. and Ngo, Chong-Wah},
 title = {Evaluating Bag-of-visual-words Representations in Scene Classification},
 booktitle = {Proceedings of the International Workshop on Workshop on Multimedia Information Retrieval},
 series = {MIR '07},
 year = {2007},
 isbn = {978-1-59593-778-0},
 location = {Augsburg, Bavaria, Germany},
 pages = {197--206},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1290082.1290111},
 doi = {10.1145/1290082.1290111},
 acmid = {1290111},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {bag-of-visual-words, keypoint, local interest point, scene classification},
} 

@Article{Lowe2004,
author="Lowe, David G.",
title="Distinctive Image Features from Scale-Invariant Keypoints",
journal="International Journal of Computer Vision",
year="2004",
month="Nov",
day="01",
volume="60",
number="2",
pages="91--110",
abstract="This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.",
issn="1573-1405",
doi="10.1023/B:VISI.0000029664.99615.94",
url="https://doi.org/10.1023/B:VISI.0000029664.99615.94"
}


@article{Jeong2009iPCAAI,
  title={iPCA: An Interactive System for PCA-based Visual Analytics},
  author={Dong Hyun Jeong and Caroline Ziemkiewicz and Brian D. Fisher and William Ribarsky and Remco Chang},
  journal={Comput. Graph. Forum},
  year={2009},
  volume={28},
  pages={767-774}
}

% to cite the sofware library
@misc{itseez2015opencv,
  title={Open Source Computer Vision Library},
  author={Itseez},
  year={2015},
  howpublished = {\url{https://github.com/itseez/opencv}}
}


@incollection{MAES1995811,
title = "Agents that Reduce work and information Overload",
editor = "RONALD M. BAECKER and JONATHAN GRUDIN and WILLIAM A.S. BUXTON and SAUL GREENBERG",
booktitle = "Readings in Humanâ€“Computer Interaction",
publisher = "Morgan Kaufmann",
pages = "811 - 821",
year = "1995",
series = "Interactive Technologies",
isbn = "978-0-08-051574-8",
doi = "https://doi.org/10.1016/B978-0-08-051574-8.50084-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780080515748500844",
author = "Pattie Maes",
address = ""
}


##############################################################
## Deep Learning: Transfer Learning, Feature Extractor
##############################################################


@article{LeCun:2015dt,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436},
  year={2015},
  publisher={Nature Publishing Group}
}


@inproceedings{imagenet_cvpr09,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
  pages={248--255},
  year={2009},
  organization={IEEE}
}
       
       
@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}



@book{hosmer2013applied,
  title={Applied logistic regression},
  author={Hosmer Jr, David W and Lemeshow, Stanley and Sturdivant, Rodney X},
  volume={398},
  year={2013},
  publisher={John Wiley \& Sons}
}



@article{yosinski2015understanding,
  title={Understanding neural networks through deep visualization},
  author={Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
  journal={arXiv preprint arXiv:1506.06579},
  year={2015}
}


@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  year={2013}
}


@article{zhou2014object,
  title={Object detectors emerge in deep scene cnns},
  author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  journal={arXiv preprint arXiv:1412.6856},
  year={2014}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{razavian2014cnn,
  title={CNN features off-the-shelf: an astounding baseline for recognition},
  author={Razavian, Ali Sharif and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
  booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference on},
  pages={512--519},
  year={2014},
  organization={IEEE}
}



@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{athiwaratkun2015feature,
  title={Feature representation in convolutional neural networks},
  author={Athiwaratkun, Ben and Kang, Keegan},
  journal={arXiv preprint arXiv:1507.02313},
  year={2015}
}

@article{mandelbaum2016word,
  title={Word embeddings and their use in sentence classification tasks},
  author={Mandelbaum, Amit and Shalev, Adi},
  journal={arXiv preprint arXiv:1610.08229},
  year={2016}
}



@INPROCEEDINGS{7797053,
author={F. Shaheen and B. Verma and M. Asafuddoula},
booktitle={2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)},
title={Impact of Automatic Feature Extraction in Deep Learning Architecture},
year={2016},
volume={},
number={},
pages={1-8},
keywords={convolution;feature extraction;image classification;learning (artificial intelligence);multilayer perceptrons;CNN;MLP;convolutional neural network;deep learning architecture;feature extraction;image classification;multilayer perceptron;Biological neural networks;Computer architecture;Feature extraction;Image classification;Machine learning;Neurons;Training},
doi={10.1109/DICTA.2016.7797053},
ISSN={},
month={Nov},}

@article{WOLD198737,
title = "Principal component analysis",
journal = "Chemometrics and Intelligent Laboratory Systems",
volume = "2",
number = "1",
pages = "37 - 52",
year = "1987",
note = "Proceedings of the Multivariate Statistical Workshop for Geologists and Geochemists",
issn = "0169-7439",
doi = "https://doi.org/10.1016/0169-7439(87)80084-9",
url = "http://www.sciencedirect.com/science/article/pii/0169743987800849",
author = "Svante Wold and Kim Esbensen and Paul Geladi"
}

@ARTICLE{391417, 
author={J. Hafner and H. S. Sawhney and W. Equitz and M. Flickner and W. Niblack}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Efficient color histogram indexing for quadratic form distance functions}, 
year={1995}, 
volume={17}, 
number={7}, 
pages={729-736}, 
keywords={visual databases;computational complexity;image colour analysis;indexing;information retrieval;image matching;query processing;color histogram indexing;quadratic form distance functions;color based image retrieval;match measure;low dimension distance measure;color distributions;lower bounds;time complexity;image databases;image querying;feature matching;Histograms;Indexing;Character recognition;Feature extraction;Pattern recognition;Computer vision;Data mining;Pattern analysis;Machine vision;Computational complexity}, 
doi={10.1109/34.391417}, 
ISSN={0162-8828}, 
month={July},}

@inproceedings{Razavian:wa,
  title={CNN features off-the-shelf: an astounding baseline for recognition},
  author={Razavian, Ali Sharif and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
  booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference on},
  pages={512--519},
  year={2014},
  organization={IEEE}
}


@inproceedings{Yosinski:wc,
 author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
 title = {How Transferable Are Features in Deep Neural Networks?},
 booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
 series = {NIPS'14},
 year = {2014},
 location = {Montreal, Canada},
 pages = {3320--3328},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2969033.2969197},
 acmid = {2969197},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 


@inproceedings{pennington2014glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}


@inproceedings{Self:2016:BGU:2939502.2939505,
 author = {Self, Jessica Zeitz and Vinayagam, Radha Krishnan and Fry, J. T. and North, Chris},
 title = {Bridging the Gap Between User Intention and Model Parameters for Human-in-the-loop Data Analytics},
 booktitle = {Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
 series = {HILDA '16},
 year = {2016},
 isbn = {978-1-4503-4207-0},
 location = {San Francisco, California},
 pages = {3:1--3:6},
 articleno = {3},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2939502.2939505},
 doi = {10.1145/2939502.2939505},
 acmid = {2939505},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {object-level interaction, usability, visual analytics},
} 

##############################################################
## Deep Vis, Deep learning visualization
##############################################################

@techreport{self2015designing,
  title={Designing for interactive dimension reduction visual analytics tools to explore high-dimensional data},
  author={Self, Jessica Zeitz and Hu, Xinran and House, Leanna and North, Chris},
  year={2015},
  institution={Technical report, Department of Computer Science, Virginia Tech, Blacksburg, Virginia}
}


@article{SACHA2017164,
title = "What you see is what you can change: Human-centered machine learning by interactive visualization",
journal = "Neurocomputing",
volume = "268",
pages = "164 - 175",
year = "2017",
note = "Advances in artificial neural networks, machine learning and computational intelligence",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2017.01.105",
url = "http://www.sciencedirect.com/science/article/pii/S0925231217307609",
author = "Dominik Sacha and Michael Sedlmair and Leishi Zhang and John A. Lee and Jaakko Peltonen and Daniel Weiskopf and Stephen C. North and Daniel A. Keim",
keywords = "Machine learning, Information visualization, Interaction, Visual analytics"
}

@ARTICLE{7536654, 
author={M. Liu and J. Shi and Z. Li and C. Li and J. Zhu and S. Liu}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={Towards Better Analysis of Deep Convolutional Neural Networks}, 
year={2017}, 
volume={23}, 
number={1}, 
pages={91-100}, 
keywords={convolution;data visualisation;directed graphs;edge detection;matrix algebra;neural nets;biclustering-based edge bundling method;deep CNN;deep convolutional neural networks;directed acyclic graph;hierarchical rectangle packing algorithm;high-quality deep models;hybrid visualization;image classification;matrix reordering algorithm;neuron cluster;pattern recognition tasks;visual analytics approach;visual clutter reduction;Clustering algorithms;Image edge detection;Neural networks;Neurons;Training;Visual analytics;Deep convolutional neural networks;biclustering;edge bundling;matrix reordering;rectangle packing}, 
doi={10.1109/TVCG.2016.2598831}, 
ISSN={1077-2626}, 
month={Jan},}


@article{Wongsuphasawat:bb,
author={K. Wongsuphasawat and D. Smilkov and J. Wexler and J. Wilson and D. ManÃ© and D. Fritz and D. Krishnan and F. B. ViÃ©gas and M. Wattenberg}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow}, 
year={2018}, 
volume={24}, 
number={1}, 
pages={1-12}, 
keywords={data flow graphs;data visualisation;graph theory;learning (artificial intelligence);deep learning models;TensorFlow Graph Visualizer;TensorFlow machine intelligence platform;complex machine learning architectures;graph transformations;standard layout techniques;legible interactive diagram;decouple noncritical nodes;clustered graph;hierarchical structure;nested structure;stable cluster expansion;responsive cluster expansion;dataflow graphs;user feedback;Visualization;Layout;Machine learning;Computational modeling;Tools;Neural networks;Standards;Neural Network;Graph Visualization;Dataflow Graph;Clustered Graph}, 
doi={10.1109/TVCG.2017.2744878}, 
ISSN={1077-2626}, 
month={Jan},
}


@article{Smilkov:2017to,
author = {Smilkov, Daniel and Carter, Shan and Sculley, D and Vi{\'e}gas, Fernanda B and Wattenberg, Martin},
title = {{Direct-Manipulation Visualization of Deep Networks}},
journal = {arxiv.org
},
year = {2017},
eprint = {1708.03788},
eprinttype = {arxiv},
month = aug
}

@incollection{Zeiler:2014fr,
author = {Zeiler, Matthew D and Fergus, Rob},
title = {{Visualizing and Understanding Convolutional Networks}},
booktitle = {Computer Vision {\textendash} ECCV 2014},
year = {2014},
pages = {818--833},
publisher = {Springer, Cham},
address = {Cham},
month = sep
}



@inproceedings{Girshick:vu,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={580--587},
  year={2014}
}


@book{munzner2014visualization,
  title={Visualization analysis and design},
  author={Munzner, Tamara},
  year={2014},
  publisher={CRC press}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  year={2016},
  publisher={MIT press Cambridge}
}


@article{Zeitz:2018:BIV:3144687.3144715,
 author = {Self, Jessica Zeitz and Dowling, Michelle and Wenskovitch, John and Crandell, Ian and Wang, Ming and House, Leanna and Leman, Scotland and North, Chris},
 title = {Observation-Level and Parametric Interaction for High-Dimensional Data Analysis},
 journal = {ACM Trans. Interact. Intell. Syst.},
 issue_date = {July 2018},
 volume = {8},
 number = {2},
 month = jun,
 year = {2018},
 issn = {2160-6455},
 pages = {15:1--15:36},
 articleno = {15},
 numpages = {36},
 url = {http://doi.acm.org/10.1145/3158230},
 doi = {10.1145/3158230},
 acmid = {3158230},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Usability, data analysis, dimension reduction, evaluation, interaction, user interface, visual analytics},
} 


@incollection{NIPS2013_5021,
title = {Distributed Representations of Words and Phrases and their Compositionality},
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
booktitle = {Advances in Neural Information Processing Systems 26},
editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
pages = {3111--3119},
year = {2013},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf}
}

@inproceedings{Ribeiro:2016:WIT:2939672.2939778,
 author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
 title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
 booktitle = {Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '16},
 year = {2016},
 isbn = {978-1-4503-4232-2},
 location = {San Francisco, California, USA},
 pages = {1135--1144},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2939672.2939778},
 doi = {10.1145/2939672.2939778},
 acmid = {2939778},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {black box classifier, explaining machine learning, interpretability, interpretable machine learning},
} 


@inproceedings{Krizhevsky:2012:ICD:2999134.2999257,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
 series = {NIPS'12},
 year = {2012},
 location = {Lake Tahoe, Nevada},
 pages = {1097--1105},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2999134.2999257},
 acmid = {2999257},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 



##############################################################
##  Visual Analytics
##############################################################
@book{Fogarty:2008bz,
author = {Fogarty, James and Tan, Desney and Kapoor, Ashish and Winder, Simon},
title = {{CueFlik: interactive concept learning in image search}},
publisher = {ACM},
year = {2008},
series = {interactive concept learning in image search},
address = {New York, New York, USA},
month = apr
}



@inproceedings{ellis2010mastering,
  title={Mastering the information age solving problems with visual analytics},
  author={Ellis, Geoffrey and Mansmann, Florian},
  booktitle={Eurographics},
  volume={2},
  pages={5},
  year={2010}
}


@article{amershi2014power,
  title={Power to the people: The role of humans in interactive machine learning},
  author={Amershi, Saleema and Cakmak, Maya and Knox, William Bradley and Kulesza, Todd},
  journal={AI Magazine},
  volume={35},
  number={4},
  pages={105--120},
  year={2014}
}


@techreport{cook2005illuminating,
author = {J Thomas, J and A Cook, K and Electrical, Institute and Engineers, Electronics},
year = {2005},
month = {01},
pages = {},
title = {Illuminating the path: The research and development agenda for visual analytics},
isbn = {0769523234}
}


@ARTICLE{1654471, 
author={Shneiderman}, 
journal={Computer}, 
title={Direct Manipulation: A Step Beyond Programming Languages}, 
year={1983}, 
volume={16}, 
number={8}, 
pages={57-69}, 
keywords={Computer languages;Displays;Interactive systems;Power system modeling;Command languages;Office automation;User interfaces;Human factors;Computer interfaces;Publishing}, 
doi={10.1109/MC.1983.1654471}, 
ISSN={0018-9162}, 
month={Aug},}


@Article{Weiss2016,
author="Weiss, Karl
and Khoshgoftaar, Taghi M.
and Wang, DingDing",
title="A survey of transfer learning",
journal="Journal of Big Data",
year="2016",
month="May",
day="28",
volume="3",
number="1",
pages="9",
abstract="Machine learning and data mining techniques have been used in numerous real-world applications. An assumption of traditional machine learning methodologies is the training data and testing data are taken from the same domain, such that the input feature space and data distribution characteristics are the same. However, in some real-world machine learning scenarios, this assumption does not hold. There are cases where training data is expensive or difficult to collect. Therefore, there is a need to create high-performance learners trained with more easily obtained data from different domains. This methodology is referred to as transfer learning. This survey paper formally defines transfer learning, presents information on current solutions, and reviews applications applied to transfer learning. Lastly, there is information listed on software downloads for various transfer learning solutions and a discussion of possible future research work. The transfer learning solutions surveyed are independent of data size and can be applied to big data environments.",
issn="2196-1115",
doi="10.1186/s40537-016-0043-6",
url="https://doi.org/10.1186/s40537-016-0043-6"
}




@INPROCEEDINGS{7344858, 
author={J. M. Kanter and K. Veeramachaneni}, 
booktitle={2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)}, 
title={Deep feature synthesis: Towards automating data science endeavors}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-10}, 
keywords={data analysis;Gaussian processes;learning (artificial intelligence);deep feature synthesis;data science endeavor automation;data science machine;feature generation;relational datasets;mathematical functions;generalizable machine learning pipeline;Gaussian copula process;Feature extraction;Predictive models;Machine learning algorithms;Prediction algorithms;Data models;Algorithm design and analysis;Data mining}, 
doi={10.1109/DSAA.2015.7344858}, 
ISSN={}, 
month={Oct},}

@article{szostak2011complex,
  author = {Szostak, Rick},
  year = {2011},
  title = {Complex concepts into basic concepts},
  journal = {Journal of the American Society for Information Science and Technology},
  publisher = {Wiley Online Library},
  issn = {1532-2890},
  doi = {10.1002/asi.21635},
  volume = {62},
  month = {11},
  pages = {2247--2265},
  number = {11},
  url = {http:https://doi.org/10.1002/asi.21635},
  abstract = {Interdisciplinary communication, and thus the rate of progress in scholarly understanding, would be greatly enhanced if scholars had access to a universal classification of documents or ideas not grounded in particular disciplines or cultures. Such a classification is feasible if complex concepts can be understood as some combination of more basic concepts. There appear to be five main types of concept theory in the philosophical literature. Each provides some support for the idea of breaking complex into basic concepts that can be understood across disciplines or cultures, but each has detractors. None of these criticisms represents a substantive obstacle to breaking complex concepts into basic concepts within information science. Can we take the subject entries in existing universal but discipline-based classifications, and break these into a set of more basic concepts that can be applied across disciplinary classes? The author performs this sort of analysis for Dewey classes 300 to 339.9. This analysis will serve to identify the sort of â€˜basic conceptsâ€™ that would lie at the heart of a truly universal classification. There are two key types of basic concept: the things we study (individuals, rocks, trees), and the relationships among these (talking, moving, paying).}
}



@article{goodman2008rational,
  title={A rational analysis of rule-based concept learning},
  author={Goodman, Noah D and Tenenbaum, Joshua B and Feldman, Jacob and Griffiths, Thomas L},
  journal={Cognitive science},
  volume={32},
  number={1},
  pages={108--154},
  year={2008},
  publisher={Wiley Online Library}
}



@INPROCEEDINGS{1382935, 
author={Pak Chung Wong and B. Hetzler and C. Posse and M. Whiting and S. Havre and N. Cramer and Anuj Shah and M. Singhal and A. Turner and J. Thomas}, 
booktitle={IEEE Symposium on Information Visualization}, 
title={IN-SPIRE InfoVis 2004 Contest Entry}, 
year={2004}, 
volume={}, 
number={}, 
pages={r2-r2}, 
keywords={Visualization;Algorithm design and analysis;Laboratories;Research and development;Text analysis;Abstracts;Collaborative tools;Computerized monitoring}, 
doi={10.1109/INFVIS.2004.37}, 
ISSN={1522-404X}, 
month={Oct},}


@ARTICLE{7160906, 
author={A. Endert and R. Chang and C. North and M. Zhou}, 
journal={IEEE Computer Graphics and Applications}, 
title={Semantic Interaction: Coupling Cognition and Computation through Usable Interactive Analytics}, 
year={2015}, 
volume={35}, 
number={4}, 
pages={94-99}, 
keywords={data analysis;data visualisation;user interfaces;semantic interaction;usable interactive analytics;visual analytics;visual exploration;Pacific Northwest National Laboratory;PNNL workshop;user interaction;Visual analytics;Computational modeling;Semantics;Analytical models;Data models;Cognition;computer graphics;visualization;visual analytics;information visualization;semantic interaction;sensemaking}, 
doi={10.1109/MCG.2015.91}, 
ISSN={0272-1716}, 
month={July},}


@article{pirolli_2005,
  abstract = {There are a relatively few open literature reports
that provide empirical descriptive studies of intelligence
analysis and that link these into the
context of expertise and work. This paper, based
on first results from a cognitive task analysis and
verbal protocols give a broad brush description
of intelligence analysis as an example of sensemaking.
It then suggests some possible leverage
points where technology might be applied.},
  added-at = {2009-09-14T09:44:22.000+0200},
  author = {Pirolli, Peter and Card, Stuart},
  biburl = {https://www.bibsonomy.org/bibtex/2ec59366c14533aef8ddd506fd2c95802/tobold},
  booktitle = {Proceedings of International Conference on Intelligence Analysis},
  interhash = {12c29c43a2393e7e9b9bd1650a7669c0},
  intrahash = {ec59366c14533aef8ddd506fd2c95802},
  keywords = {information_foraging sensemaking sota_brainwave},
  pages = {2--4},
  timestamp = {2009-10-26T10:46:39.000+0100},
  title = {The sensemaking process and leverage points for analyst technology as identified through cognitive task analysis},
  url = {https://analysis.mitre.org/proceedings/Final_Papers_Files/206_Camera_Ready_Paper.pdf},
  year = 2005
}



@article{Sacha:2017ci,
author = {Sacha, Dominik and Sedlmair, Michael and Zhang, Leishi and Lee, John Aldo and Peltonen, Jaakko and Weiskopf, Daniel and North, Stephen C and Keim, Daniel A},
title = {{What you see is what you can change - Human-centered machine learning by interactive visualization.}},
journal = {Neurocomputing},
year = {2017},
volume = {268},
pages = {164--175}
}



@article{Sacha_Knowledge_2014,
  title={Knowledge generation model for visual analytics},
  author={Sacha, Dominik and Stoffel, Andreas and Stoffel, Florian and Kwon, Bum Chul and Ellis, Geoffrey and Keim, Daniel A},
  journal={IEEE transactions on visualization and computer graphics},
  volume={20},
  number={12},
  pages={1604--1613},
  year={2014},
  publisher={IEEE}
}




@article{Endert:he,
  title={Semantic interaction for sensemaking: inferring analytical reasoning for model steering},
  author={Endert, Alex and Fiaux, Patrick and North, Chris},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={18},
  number={12},
  pages={2879--2888},
  year={2012},
  publisher={IEEE}
}


@inproceedings{Bradel:dd,
author = {Bradel, Lauren and North, Chris and House, Leanna and Leman, Scotland},
title = {{Multi-model semantic interaction for text analytics}},
booktitle = {2014 IEEE Conference on Visual Analytics Science and Technology (VAST)},
pages = {163--172},
publisher = {IEEE}
}




@inproceedings{Endert:ji,
author = {Endert, Alex and Han, Chao and Maiti, Dipayan and House, Leanna and Leman, Scotland and North, Chris},
title = {{Observation-level interaction with statistical models for visual analytics}},
booktitle = {2011 IEEE Conference on Visual Analytics Science and Technology (VAST)},
pages = {121--130},
publisher = {IEEE}
}

@inproceedings{endert2012semantic,
  title={Semantic interaction for visual text analytics},
  author={Endert, Alex and Fiaux, Patrick and North, Chris},
  booktitle={Proceedings of the SIGCHI conference on Human factors in computing systems},
  pages={473--482},
  year={2012},
  organization={ACM}
}

@article{house2015bayesian,
 author = {House, Leanna and Leman, Scotland and Han, Chao},
 title = {Bayesian Visual Analytics: BaVA},
 journal = {Stat. Anal. Data Min.},
 issue_date = {February 2015},
 volume = {8},
 number = {1},
 month = feb,
 year = {2015},
 issn = {1932-1864},
 pages = {1--13},
 numpages = {13},
 url = {http://dx.doi.org/10.1002/sam.11253},
 doi = {10.1002/sam.11253},
 acmid = {2913424},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
 keywords = {Bayesian, Ssense-making, data mining, elicitation, high-dimensional data, sequential updating, statistical visualization, visual analytics},
} 


@article{bishop1998gtm,
  title={GTM: The generative topographic mapping},
  author={Bishop, Christopher M and Svens{\'e}n, Markus and Williams, Christopher KI},
  journal={Neural computation},
  volume={10},
  number={1},
  pages={215--234},
  year={1998},
  publisher={MIT Press}
}


@book{schiffman1981introduction,
  title={Introduction to multidimensional scaling: Theory, methods, and applications},
  author={Schiffman, Susan S and Reynolds, M Lance and Young, Forrest W},
  year={1981},
  publisher={Emerald Group Publishing}
}


@article{tipping1999mixtures,
  title={Mixtures of probabilistic principal component analyzers},
  author={Tipping, Michael E and Bishop, Christopher M},
  journal={Neural computation},
  volume={11},
  number={2},
  pages={443--482},
  year={1999},
  publisher={MIT Press}
}

@article{Leman:2013it,
author = {Leman, Scotland C and House, Leanna and Maiti, Dipayan and Endert, Alex and North, Chris},
title = {{Visual to Parametric Interaction (V2PI)}},
journal = {PLOS ONE},
year = {2013},
volume = {8},
number = {3},
pages = {e50474},
month = mar
}





@article{endert2016semantic,
  title={Semantic interaction for visual analytics: inferring analytical reasoning for model steering},
  author={Endert, Alex},
  journal={Synthesis Lectures on Visualization},
  volume={4},
  number={2},
  pages={1--99},
  year={2016},
  publisher={Morgan \& Claypool Publishers}
}

@article{House:2015hs,
author = {House, Leanna and Leman, Scotland and Han, Chao},
title = {{Bayesian visual analytics: BaVA}},
journal = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
year = {2015},
volume = {8},
number = {1},
pages = {1--13},
month = jan
}

##############################################################
## Misc. Software, Data, and Open souce
##############################################################
@article{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@inproceedings{coates2011analysis,
  title={An analysis of single-layer networks in unsupervised feature learning},
  author={Coates, Adam and Ng, Andrew and Lee, Honglak},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={215--223},
  year={2011}
}

@inproceedings{jia2014caffe,
  title={Caffe: Convolutional architecture for fast feature embedding},
  author={Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  booktitle={Proceedings of the 22nd ACM international conference on Multimedia},
  pages={675--678},
  year={2014},
  organization={ACM}
}

@inproceedings{bergstra2010theano,
  title={Theano: A CPU and GPU math compiler in Python},
  author={Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'e}d{\'e}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
  booktitle={Proc. 9th Python in Science Conf},
  volume={1},
  year={2010}
}


@techreport{collobert2002torch,
  title={Torch: a modular machine learning software library},
  author={Collobert, Ronan and Bengio, Samy and Mari{\'e}thoz, Johnny},
  year={2002},
  institution={Idiap}
}

@article{abadi2016tensorflow,
  title={Tensorflow: Large-scale machine learning on heterogeneous distributed systems},
  author={Abadi, Mart{\'\i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and others},
  journal={arXiv preprint arXiv:1603.04467},
  year={2016}
}

@article{salimans2017pixelcnn++,
  title={Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications},
  author={Salimans, Tim and Karpathy, Andrej and Chen, Xi and Kingma, Diederik P},
  journal={arXiv preprint arXiv:1701.05517},
  year={2017}
}


@article{liuimage,
  title={Image Classification for Dogs and Cats},
  author={Liu, Bang and Liu, Yan and Zhou, Kai}
}


@ARTICLE{5288526, 
author={S. J. Pan and Q. Yang}, 
journal={IEEE Transactions on Knowledge and Data Engineering}, 
title={A Survey on Transfer Learning}, 
year={2010}, 
volume={22}, 
number={10}, 
pages={1345-1359}, 
keywords={knowledge engineering;learning by example;optimisation;unsupervised learning;data mining;inductive transfer learning;knowledge transfer;machine learning;transductive transfer learning;unsupervised transfer learning;Data mining;Knowledge engineering;Knowledge transfer;Labeling;Learning systems;Machine learning;Machine learning algorithms;Space technology;Testing;Training data;Transfer learning;data mining.;machine learning;survey}, 
doi={10.1109/TKDE.2009.191}, 
ISSN={1041-4347}, 
month={Oct},}


@article{kim2017interpretability,
  title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and Sayres, Rory},
  journal={arXiv preprint arXiv:1711.11279},
  year={2017}
}

@inproceedings{Krause:2016:IPV:2858036.2858529,
 author = {Krause, Josua and Perer, Adam and Ng, Kenney},
 title = {Interacting with Predictions: Visual Inspection of Black-box Machine Learning Models},
 booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '16},
 year = {2016},
 isbn = {978-1-4503-3362-7},
 location = {San Jose, California, USA},
 pages = {5686--5697},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2858036.2858529},
 doi = {10.1145/2858036.2858529},
 acmid = {2858529},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {interactive machine learning, partial dependence, predictive modeling},
}


@article{DBLP:journals/corr/HodasE16,
  author    = {Nathan Oken Hodas and
               Alex Endert},
  title     = {Adding Semantic Information into Data Models by Learning Domain Expertise
               from User Interaction},
  journal   = {CoRR},
  volume    = {abs/1604.02935},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.02935},
  archivePrefix = {arXiv},
  eprint    = {1604.02935},
  timestamp = {Mon, 13 Aug 2018 16:47:19 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HodasE16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{7534876, 
author={B. C. {Kwon} and H. {Kim} and E. {Wall} and J. {Choo} and H. {Park} and A. {Endert}}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={AxiSketcher: Interactive Nonlinear Axis Mapping of Visualizations through User Drawings}, 
year={2017}, 
volume={23}, 
number={1}, 
pages={221-230}, 
keywords={data analysis;data visualisation;AxiSketcher approach;interactive nonlinear axis mapping;visualization mapping;user drawings;visual analytics techniques;domain knowledge;attribute-level knowledge;sketching methods;interactive visualization;Data visualization;Visual analytics;Analytical models;Data models;Automobiles;Computational modeling;Manifolds;axis mapping;interactive model steering;sketch;axis visualization;human-centered visual analytics}, 
doi={10.1109/TVCG.2016.2598446}, 
ISSN={1077-2626}, 
month={Jan},}


@inproceedings{taskonomy2018,
title={Taskonomy: Disentangling Task Transfer Learning},
author={Amir R. Zamir and Alexander Sax and William B. Shen and Leonidas J. Guibas and Jitendra Malik and Silvio Savarese},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2018},
organization={IEEE},
}


@article{hohman2018visual,
  title={Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers},
  author={Hohman, Fred and Kahng, Minsuk and Pienta, Robert and Chau, Duen Horng},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2018},
  publisher={IEEE}
}

@ARTICLE {8402187,
author = {J. Choo and S. Liu},
journal = {IEEE Computer Graphics and Applications},
title = {Visual Analytics for Explainable Deep Learning},
year = {2018},
volume = {38},
number = {04},
issn = {0272-1716},
pages = {84-92},
keywords = {machine learning;visual analytics;computational modeling;predictive models;data visualization},
doi = {10.1109/MCG.2018.042731661},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jul}
}


@ARTICLE{8265023, 
author={H. {Cheng} and A. {Cardone} and S. {Jain} and E. {Krokos} and K. {Narayan} and S. {Subramaniam} and A. {Varshney}}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={Deep-Learning-Assisted Volume Visualization}, 
year={2019}, 
volume={25}, 
number={2}, 
pages={1378-1391}, 
keywords={data analysis;data visualisation;learning (artificial intelligence);neural nets;deep-learning-assisted volume visualization;machine learning methods;high-dimensional deep features;deep-learning-assisted technique;electron microscopy volumes;spectral methods;magnetic resonance imaging;Feature extraction;Neurons;Complexity theory;Convolution;Isosurfaces;Training;Volume visualization;convolutional neural networks}, 
doi={10.1109/TVCG.2018.2796085}, 
ISSN={1077-2626}, 
month={Feb},}


@article{DBLP:journals/corr/abs-1802-05316,
  author    = {Meg Pirrung and
               Nathan Hilliard and
               Art{\"{e}}m Yankov and
               Nancy O'Brien and
               Paul Weidert and
               Courtney D. Corley and
               Nathan O. Hodas},
  title     = {Sharkzor: Interactive Deep Learning for Image Triage, Sort and Summary},
  journal   = {CoRR},
  volume    = {abs/1802.05316},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.05316},
  archivePrefix = {arXiv},
  eprint    = {1802.05316},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1802-05316},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{WANG201766,
title = "Interactive deep learning method for segmenting moving objects",
journal = "Pattern Recognition Letters",
volume = "96",
pages = "66 - 75",
year = "2017",
note = "Scene Background Modeling and Initialization",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2016.09.014",
url = "http://www.sciencedirect.com/science/article/pii/S0167865516302471",
author = "Yi Wang and Zhiming Luo and Pierre-Marc Jodoin",
keywords = "Motion detection, Ground truthing, Convolutional neural network",
abstract = "With the increasing number of machine learning methods used for segmenting images and analyzing videos, there has been a growing need for large datasets with pixel accurate ground truth. In this letter, we propose a highly accurate semi-automatic method for segmenting foreground moving objects pictured in surveillance videos. Given a limited number of user interventions, the goal of the method is to provide results sufficiently accurate to be used as ground truth. In this paper, we show that by manually outlining a small number of moving objects, we can get our model to learn the appearance of the background and the foreground moving objects. Since the background and foreground moving objects are highly redundant from one image to another (videos come from surveillance cameras) the model does not need a large number of examples to accurately fit the data. Our end-to-end model is based on a multi-resolution convolutional neural network (CNN) with a cascaded architecture. Tests performed on the largest publicly-available video dataset with pixel accurate groundtruth (changdetection.net) reveal that on videos from 11 categories, our approach has an average F-measure of 0.95 which is within the error margin of a human being. With our model, the amount of manual work for ground truthing a video gets reduced by a factor of up to 40. Code is made publicly available at: https://github.com/zhimingluo/MovingObjectSegmentation"
}


@article{yu15lsun,
    Author = {Yu, Fisher and Zhang, Yinda and Song, Shuran and Seff, Ari and Xiao, Jianxiong},
    Title = {LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop},
    Journal = {arXiv preprint arXiv:1506.03365},
    Year = {2015}
}


@article{10.1371/journal.pone.0129122,
    author = {Han, Chao AND House, Leanna AND Leman, Scotland C.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Expert-Guided Generative Topographical Modeling with Visual to Parametric Interaction},
    year = {2016},
    month = {02},
    volume = {11},
    url = {https://doi.org/10.1371/journal.pone.0129122},
    pages = {1-14},
    abstract = {Introduced by Bishop et al. in 1996, Generative Topographic Mapping (GTM) is a powerful nonlinear latent variable modeling approach for visualizing high-dimensional data. It has shown useful when typical linear methods fail. However, GTM still suffers from drawbacks. Its complex parameterization of data make GTM hard to fit and sensitive to slight changes in the model. For this reason, we extend GTM to a visual analytics framework so that users may guide the parameterization and assess the data from multiple GTM perspectives. Specifically, we develop the theory and methods for Visual to Parametric Interaction (V2PI) with data using GTM visualizations. The result is a dynamic version of GTM that fosters data exploration. We refer to the new version as V2PI-GTM. In this paper, we develop V2PI-GTM in stages and demonstrate its benefits within the context of a text mining case study.},
    number = {2},
    doi = {10.1371/journal.pone.0129122}
}